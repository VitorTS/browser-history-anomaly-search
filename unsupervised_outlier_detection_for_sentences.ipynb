{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\work\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\work\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.reset_default_graph()\n",
    "import tensorflow_hub as hub\n",
    "import tf_sentencepiece\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "#interactive stuff\n",
    "import io\n",
    "from IPython.display import clear_output\n",
    "from ipywidgets import interactive, FileUpload, Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #teste if gpu is enabled\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "    with tf.device('/gpu:0'):\n",
    "        a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "        b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "        c = tf.matmul(a, b)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        print (sess.run(c))\n",
    "    # should be\n",
    "    #   [[22. 28.]\n",
    "    #   [49. 64.]]\n",
    "except:\n",
    "    print(\"no GPU, ah :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Universal Sentence encoder (USE)\n",
    "use_module_url = \"https://tfhub.dev/google/universal-sentence-encoder-multilingual/1\"\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    text_input = tf.placeholder(dtype=tf.string, shape=[None])\n",
    "    embed_module = hub.Module(use_module_url)\n",
    "    embedded_text = embed_module(text_input)\n",
    "    init_op = tf.group([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "g.finalize()\n",
    "\n",
    "config = tf.ConfigProto(inter_op_parallelism_threads=1,\n",
    "                   intra_op_parallelism_threads=1)\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "session = tf.Session(graph=g, config=config)\n",
    "\n",
    "session.run(init_op)\n",
    "\n",
    "\n",
    "\n",
    "def generate_embeddings(messages_in):\n",
    "    return session.run(embedded_text, feed_dict={text_input: messages_in})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_data(df):\n",
    "    #remove duplicates, NaNs etc\n",
    "    df.drop_duplicates(subset=['title'],inplace=True)\n",
    "\n",
    "    df.dropna(\n",
    "        axis=0,\n",
    "        how='any',\n",
    "        thresh=None,\n",
    "        subset=['title'],\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    df['index'] = df.index\n",
    "    \n",
    "    #clear non meaningful words\n",
    "    import re\n",
    "\n",
    "    noiseWords = ['Google Search', '|', '%', '.', ' â€” ', '/']\n",
    "    big_regex = re.compile('|'.join(map(re.escape, noiseWords)))\n",
    "    df['title'] = df['title'].apply(lambda x : big_regex.sub(\"\", x) )\n",
    "\n",
    "    def remove_non_nouns(lines):\n",
    "        is_noun = lambda pos: pos[:2] == 'NN'\n",
    "        tokenized = nltk.word_tokenize(lines)\n",
    "        return ' '.join( [word for (word, pos) in nltk.pos_tag(tokenized) if is_noun(pos)] )\n",
    "\n",
    "    df['title'] = df['title'].apply(remove_non_nouns);\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_most_common_sentence(df):\n",
    "    #get word frequency\n",
    "    tokens = nltk.tokenize.word_tokenize(' '.join(df[\"title\"]))\n",
    "    freq = nltk.FreqDist(tokens)\n",
    "    \n",
    "    compare_to_top = 10\n",
    "    top_n_words_sentence = ' '.join([i[0] for i in freq.most_common(compare_to_top)])\n",
    "    return df.append({'title': top_n_words_sentence, 'type': 1}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_narest_neighbor(df, use_embeddings):\n",
    "    #return df\n",
    "    #calculat the distance between USE embeddings\n",
    "    from annoy import AnnoyIndex\n",
    "    nn_tree = AnnoyIndex(512, 'euclidean')\n",
    "    for idx, e in enumerate(use_embeddings):\n",
    "        nn_tree.add_item(idx, e)\n",
    "    nn_tree.build(10)\n",
    "    \n",
    "    idxs = nn_tree.get_nns_by_item(df.last_valid_index(), len(df))\n",
    "    \n",
    "    idxs.reverse() #get furthest neighhbors\n",
    "    \n",
    "    return df.reindex(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d3d925ac934d63855744c1a8e0a2df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid black', height='70px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5922cb98d3fa4a3786eab48188c8e492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid black', height='400px', overflow='scroll'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outFileUpload = Output(layout={'border': '1px solid black', 'height': '70px'})\n",
    "out = Output(layout={'border': '1px solid black', 'height': '400px', 'overflow': 'scroll'})\n",
    "\n",
    "uploader = FileUpload(\n",
    "    accept='.csv,.txt',\n",
    "    multiple=False\n",
    ")\n",
    "\n",
    "with outFileUpload:\n",
    "    pd.set_option(\"display.max_rows\", None)\n",
    "    display(uploader)\n",
    "\n",
    "@out.capture()\n",
    "def on_upload_change(change):\n",
    "    df = pd.read_csv(io.BytesIO(change['owner'].data[0]))\n",
    "\n",
    "    out.clear_output(wait=True)\n",
    "    \n",
    "    if not 'title' in df:\n",
    "        return display(\"error: csv file needs to have a 'title' column\")\n",
    "    \n",
    "    df = clear_data(df)\n",
    "    df = append_most_common_sentence(df)\n",
    "    \n",
    "    compSentence = df.tail(1)\n",
    "    \n",
    "    use_embeddings = generate_embeddings(df['title'])\n",
    "    #use_embeddings = np.load('embeddings.npy')\n",
    "    df = sort_by_narest_neighbor(df, use_embeddings)\n",
    "    \n",
    "    df.drop(compSentence.index, inplace=True)\n",
    "    \n",
    "    display(\"comparing sentences to '\" + compSentence['title'].values[0] + \"''\")\n",
    "    \n",
    "    display(df[['date', 'time', 'title']])\n",
    "        \n",
    "uploader.observe(on_upload_change, names='_counter')\n",
    "\n",
    "display(outFileUpload)\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
